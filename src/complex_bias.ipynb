{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00562e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelParams, load_model, greedy_predict, tokens_to_text\n",
    "from hooks import HookPoint, register_decoder_hook\n",
    "from data import generate_dataset_pairs\n",
    "from nesymres.architectures.data import tokenize\n",
    "from nesymres.dataset.generator import Generator\n",
    "import torch\n",
    "import re\n",
    "import sympy\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "device = \"cpu\" # NOTE: change to cuda if your GPU can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d1dcb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.3.3 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../res/100m.ckpt`\n"
     ]
    }
   ],
   "source": [
    "model = load_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d39d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth function\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x_{3} - \\frac{\\sin{\\left(e^{\\cos{\\left(x_{3} \\right)}} \\right)} \\sin{\\left(\\sin{\\left(\\cos{\\left(x_{3} \\right)} \\right)} \\right)}}{\\cos{\\left(x_{1} \\right)}} - \\left|{x_{3}}\\right|$"
      ],
      "text/plain": [
       "x_3 - sin(exp(cos(x_3)))*sin(sin(cos(x_3)))/cos(x_1) - Abs(x_3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys(['equations', 'X0', 'y0', 'X1', 'y1']),\n",
       " torch.Size([1, 10000, 3]),\n",
       " torch.Size([1, 50, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42) # 42\n",
    "\n",
    "complexity_dataset = generate_dataset_pairs(\"complexity-bias\", 10_000, 1, model.model_cfg, model.eq_cfg, second_dataset_sample_rate=200)\n",
    "\n",
    "print(\"Ground truth function\")\n",
    "display(sympy.sympify(complexity_dataset[\"equations\"][0][0]))\n",
    "\n",
    "complexity_dataset.keys(), complexity_dataset[\"X0\"].shape, complexity_dataset[\"X1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3cd6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  9,  6,  9, 18, 27,  7,  6, 18, 27, 18, 19, 12,  4, 27, 18, 20, 16,\n",
       "         12,  6, 20, 20, 12,  6,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equation_to_tokens(eq: str, eq_cfg: Dict):\n",
    "    eq_sympy_prefix = Generator.sympy_to_prefix(sympy.sympify(eq))\n",
    "    return tokenize(eq_sympy_prefix, eq_cfg[\"word2id\"])\n",
    "\n",
    "tokenized_eqs = torch.zeros(len(complexity_dataset[\"equations\"]), model.model_cfg.architecture.length_eq, dtype=torch.long)\n",
    "\n",
    "for i, eq in enumerate(complexity_dataset[\"equations\"]):\n",
    "    tokenized = torch.tensor(equation_to_tokens(eq[0], model.eq_cfg))\n",
    "    tokenized_eqs[i, :tokenized.shape[-1]] = tokenized\n",
    "tokenized_eqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d7eb995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2921965662959739"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_complexity_disparity(model: ModelParams, X: torch.Tensor, y: torch.Tensor, tokenized_eqs: torch.Tensor):\n",
    "    COMPLEX_OPS = ['acos', 'asin', 'atan', 'cos', 'cosh', 'coth', 'exp', 'ln', 'pow', 'sin', 'sinh', 'sqrt', 'tan', 'tanh']\n",
    "    SIMPLE_OPS = ['add', 'div', 'mul']\n",
    "\n",
    "    complex_ids = torch.tensor([model.eq_cfg[\"word2id\"][word] for word in COMPLEX_OPS], dtype=torch.long)\n",
    "    simple_ids = torch.tensor([model.eq_cfg[\"word2id\"][word] for word in SIMPLE_OPS], dtype=torch.long)\n",
    "\n",
    "    def disparity(probs: torch.Tensor) -> float:\n",
    "        \"\"\" Computes how much the given logit probabilities tend to a complex operator over a non-complex operator. \"\"\"\n",
    "        complex_prob = probs[:, complex_ids].sum(dim=-1)\n",
    "        simple_prob = probs[:, simple_ids].sum(dim=-1)\n",
    "        return torch.mean(complex_prob - simple_prob).item()\n",
    "\n",
    "    disparities = []\n",
    "\n",
    "    # initial token prediction, this initializes the sequence and caches the encoder embedding (saves computation time).\n",
    "    probs, _, enc_embed = greedy_predict(model.model, model.params_fit, X, y)\n",
    "    disparities.append(disparity(probs))\n",
    "\n",
    "    # to test the model, we use the ground truth sequence at each position\n",
    "    for i in range(2, tokenized_eqs.shape[-1]):\n",
    "        seq = tokenized_eqs.clone()\n",
    "        seq[:, i:] = 0\n",
    "        probs, _, _ = greedy_predict(model.model, model.params_fit, enc_embed=enc_embed, sequence=seq)\n",
    "        disparities.append(disparity(probs))\n",
    "\n",
    "    return np.mean(disparities)\n",
    "\n",
    "bias0 = compute_mean_complexity_disparity(model, complexity_dataset[\"X0\"], complexity_dataset[\"y0\"], tokenized_eqs)\n",
    "bias1 = compute_mean_complexity_disparity(model, complexity_dataset[\"X1\"], complexity_dataset[\"y1\"], tokenized_eqs)\n",
    "\n",
    "bias0 - bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b930e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth function\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x_{3} - \\frac{\\sin{\\left(e^{\\cos{\\left(x_{3} \\right)}} \\right)} \\sin{\\left(\\sin{\\left(\\cos{\\left(x_{3} \\right)} \\right)} \\right)}}{\\cos{\\left(x_{1} \\right)}} - \\left|{x_{3}}\\right|$"
      ],
      "text/plain": [
       "x_3 - sin(exp(cos(x_3)))*sin(sin(cos(x_3)))/cos(x_1) - Abs(x_3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy predicted equation:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle c \\tan{\\left(c x_{2} + x_{1} \\right)} + x_{3} - \\left|{c + x_{3}}\\right|$"
      ],
      "text/plain": [
       "c*tan(c*x_2 + x_1) + x_3 - Abs(c + x_3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy predicted equation:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{c \\tan{\\left(x_{1} \\right)}}{x_{1}} + x_{3} - \\left|{x_{3}}\\right|$"
      ],
      "text/plain": [
       "c*tan(x_1)/x_1 + x_3 - Abs(x_3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_autocomplete(model, X, y):\n",
    "    # initial token prediction, this initializes the sequence and caches the encoder embedding (saves computation time).\n",
    "    _, seq, enc_embed = greedy_predict(model.model, model.params_fit, X, y)\n",
    "\n",
    "    # repeatedly predict next token greedily\n",
    "    for _ in range(30):\n",
    "        seq = greedy_predict(model.model, model.params_fit, enc_embed=enc_embed, sequence=seq)[1]\n",
    "\n",
    "    # this should result in (roughly) the correct equation\n",
    "    greedy_pred = tokens_to_text(seq, model.params_fit)\n",
    "\n",
    "    print(\"Greedy predicted equation:\")\n",
    "    for eq in greedy_pred:\n",
    "        display(sympy.sympify(eq))\n",
    "\n",
    "print(\"Ground truth function\")\n",
    "display(sympy.sympify(complexity_dataset[\"equations\"][0][0]))\n",
    "\n",
    "display_autocomplete(model, complexity_dataset[\"X0\"], complexity_dataset[\"y0\"])\n",
    "display_autocomplete(model, complexity_dataset[\"X1\"], complexity_dataset[\"y1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symreg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
