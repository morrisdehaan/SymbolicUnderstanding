{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_model, greedy_predict, tokens_to_text\n",
    "from hooks import HookPoint, register_decoder_hook\n",
    "from data import generate_dataset_pairs\n",
    "import torch\n",
    "import sympy\n",
    "\n",
    "device = \"cpu\" # NOTE: change to cuda if your GPU can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3293616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8196795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we uncomment the code below, we set all decoder MLP outputs to random values using interventions.\n",
    "#  As you'll see below, the model won't be able to fit the correct equation (:omg:).\n",
    "\n",
    "\"\"\"\n",
    "def test_hook(output, _hook: HookPoint):\n",
    "    return torch.randn_like(output)\n",
    "\n",
    "for layer in range(4):\n",
    "    register_decoder_hook(model.model, test_hook, HookPoint(layer, \"mlp\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_dataset = generate_dataset_pairs(\"complexity-bias\", 500, 10, model.model_cfg, model.eq_cfg, second_dataset_sample_rate=2)\n",
    "\n",
    "X = complexity_dataset[\"X0\"][0]\n",
    "y = complexity_dataset[\"y0\"][0]\n",
    "\n",
    "print(\"Ground truth function\")\n",
    "sympy.sympify(complexity_dataset[\"equations\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial token prediction, this initializes the sequence and caches the encoder embedding (saves computation time).\n",
    "tok, seq, enc_embed = greedy_predict(model.model, model.params_fit, X.unsqueeze(0), y.unsqueeze(0))\n",
    "\n",
    "# repeatedly predict next token greedily\n",
    "for i in range(30):\n",
    "    seq = greedy_predict(model.model, model.params_fit, enc_embed=enc_embed, sequence=seq)[1]\n",
    "\n",
    "# this should result in (roughly) the correct equation\n",
    "print(seq)\n",
    "greedy_pred = tokens_to_text(seq, model.params_fit)\n",
    "\n",
    "print(\"Greedy predicted equation:\")\n",
    "for eq in greedy_pred:\n",
    "    display(sympy.sympify(eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with beam search instead of greedy + constant fitting (takes a lot longer)\n",
    "output = model.fitfunc(X, y)\n",
    "# here you can see the fitted equations\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best BFGS prediction:\")\n",
    "sympy.sympify(output[\"best_bfgs_preds\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "def tokens_to_text_previous(tokens, params_fit):\n",
    "\n",
    "    for batch in tokens:\n",
    "        text = []\n",
    "        for token in batch:\n",
    "\n",
    "            if token.item() == 0 or token.item() == 2:\n",
    "                break\n",
    "            text.append(params_fit.id2word[token.item()])\n",
    "    return text\n",
    "\n",
    "# define hook to store intermediate representations (are overwritten after each auto-regressive step)\n",
    "hooked_outputs = defaultdict()\n",
    "\n",
    "def hook_intermediate_representations(output, _hook: HookPoint):\n",
    "    \"\"\"\n",
    "    This hook function is used to extract intermediate representations from the model.\n",
    "    It returns the output of the hooked component as a numpy array.\n",
    "    \"\"\"\n",
    "    if _hook.component == \"mlp\":\n",
    "        key = (_hook.component, _hook.layer)\n",
    "    else:\n",
    "        key = (_hook.component[0], _hook.component[1], _hook.layer)\n",
    "    hooked_outputs[key] = output.detach().clone().cpu().numpy()\n",
    "    return output\n",
    "\n",
    "# register hooks for all decoder layers and components\n",
    "for layer_idx in range(len(model.model.decoder_transfomer.layers)):\n",
    "    register_decoder_hook(model.model, hook_intermediate_representations, HookPoint(layer_idx, \"mlp\"))\n",
    "    for head_idx in range(model.model.decoder_transfomer.layers[layer_idx].multihead_attn.num_heads):\n",
    "\n",
    "        register_decoder_hook(model.model, hook_intermediate_representations, HookPoint(layer_idx, (\"self\", head_idx)))\n",
    "        register_decoder_hook(model.model, hook_intermediate_representations, HookPoint(layer_idx, (\"cross\", head_idx)))\n",
    "\n",
    "\n",
    "def create_dataset(bias, num_eq):\n",
    "    dataset_probing_train = generate_dataset_pairs(bias, 500, num_eq, model.model_cfg, model.eq_cfg, second_dataset_sample_rate=2)\n",
    "\n",
    "    X_train_bias1 = dataset_probing_train[\"X0\"]\n",
    "    X_train_bias2 = dataset_probing_train[\"X1\"]\n",
    "\n",
    "    y_train_bias1 = dataset_probing_train[\"y0\"]\n",
    "    y_train_bias2 = dataset_probing_train[\"y1\"]\n",
    "\n",
    "    return X_train_bias1, X_train_bias2, y_train_bias1, y_train_bias2, dataset_probing_train\n",
    "\n",
    "\n",
    "\n",
    "# run the model on the dataset and collect representations for training probe\n",
    "\n",
    "def collect_representations(X, y, sign, label_id, states, labels):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            print(i)\n",
    "            tok, seq, enc_embed = greedy_predict(model.model, model.params_fit, X[i].unsqueeze(0), y[i].unsqueeze(0))\n",
    "\n",
    "            # repeatedly predict next token greedily\n",
    "            for _ in range(30):\n",
    "                seq = greedy_predict(model.model, model.params_fit, enc_embed=enc_embed, sequence=seq)[1]\n",
    "                formula_tokens = tokens_to_text_previous(seq, model.params_fit)\n",
    "                if sign in \"\".join(formula_tokens):\n",
    "                    labels.append(label_id)\n",
    "                    for key, value in hooked_outputs.items():\n",
    "\n",
    "                        if \"mlp\" in key[0]:\n",
    "                            states[key].append(value)\n",
    "                        else:\n",
    "                            states[key].append(value[-1])\n",
    "                    break\n",
    "    return states, labels\n",
    "\n",
    "# collect representations for plus and minus\n",
    "train_split = 0.75\n",
    "test_split = 1.0 - 0.75\n",
    "num_eq = 80\n",
    "states_train = defaultdict(list)\n",
    "labels_train = []\n",
    "X_plus, X_minus, y_plus, y_minus, _ = create_dataset(\"sign-bias\", num_eq)\n",
    "n_train_samples = int(num_eq * train_split)\n",
    "collect_representations(X_plus[:n_train_samples], y_plus[:n_train_samples], \"add\", 1, states_train, labels_train)\n",
    "collect_representations(X_minus[:n_train_samples], y_minus[:n_train_samples], \"-\", 0, states_train, labels_train)\n",
    "\n",
    "# create test set\n",
    "n_test_samples = int(num_eq * test_split)\n",
    "states_test = defaultdict(list)\n",
    "labels_test = []\n",
    "collect_representations(X_plus[n_test_samples:], y_plus[n_test_samples:], \"add\", 1, states_test, labels_test)\n",
    "collect_representations(X_minus[n_test_samples:], y_minus[n_test_samples:], \"-\", 0, states_test, labels_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b289af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "probe_results = defaultdict()\n",
    "\n",
    "for key, representation in states_train.items():\n",
    "    print(f\"Training probe for {key}...\")\n",
    "\n",
    "    X_train = torch.tensor(representation).squeeze(1)\n",
    "    y_train = torch.tensor(labels_train)\n",
    "    # train a logistic regression probe\n",
    "    probe = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", max_iter=10)\n",
    "\n",
    "    probe.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the probe\n",
    "    X_test = torch.tensor(states_test[key]).squeeze(1)\n",
    "    y_test = torch.tensor(labels_test)\n",
    "    y_pred = probe.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {key}: {accuracy:.4f}\")\n",
    "    probe_results[key] = {\n",
    "        \"model\": probe,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "# print the results\n",
    "for key, result in probe_results.items():\n",
    "    print(f\"Probe for {key} achieved accuracy: {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots\n",
    "# heatmap with all the accuracies with x-axis the layers and y-axis the heads and for mlp just a strip\n",
    "# line plot with one per attnetion head and the mlp so average the scores and show the standard deviation\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "matrix_mlp = np.zeros(5)\n",
    "matrix_cross = np.zeros((len(model.model.decoder_transfomer.layers), len(range(model.model.decoder_transfomer.layers[0].multihead_attn.num_heads))))\n",
    "matrix_self = np.zeros((len(model.model.decoder_transfomer.layers), len(range(model.model.decoder_transfomer.layers[0].multihead_attn.num_heads))))\n",
    "for layer_idx in range(len(model.model.decoder_transfomer.layers)):\n",
    "    matrix_mlp[layer_idx] = probe_results[('mlp', layer_idx)]['accuracy']\n",
    "\n",
    "    for head_idx in range(model.model.decoder_transfomer.layers[layer_idx].multihead_attn.num_heads):\n",
    "\n",
    "        matrix_cross[layer_idx, head_idx] = probe_results[('cross', head_idx, layer_idx)]['accuracy']\n",
    "        matrix_self[layer_idx, head_idx] = probe_results[('self', head_idx, layer_idx)]['accuracy']\n",
    "\n",
    "# sns.heatmap(matrix_self, annot=True)\n",
    "# plt.title(\"self-attention accuracies\")\n",
    "# plt.xlabel(\"attention head\")\n",
    "# plt.ylabel(\"decoder layer\")\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# sns.heatmap(matrix_cross, annot=True)\n",
    "# plt.title(\"cross-attention accuracies\")\n",
    "# plt.xlabel(\"attention head\")\n",
    "# plt.ylabel(\"decoder layer\")\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# print(matrix_mlp.shape)\n",
    "\n",
    "aggregated_self_mean = np.mean(matrix_self, axis=1)\n",
    "aggregated_self_std = np.std(matrix_self, axis=1)\n",
    "aggregated_cross_mean = np.mean(matrix_cross, axis=1)\n",
    "aggregated_cross_std = np.std(matrix_cross, axis=1)\n",
    "print(aggregated_cross_std.shape)\n",
    "\n",
    "plt.scatter([i for i in range(1, 6)], matrix_mlp, color='r', label=\"mlp\")\n",
    "plt.scatter([i for i in range(1, 6)], aggregated_self_mean, label=\"self-attention mean\")\n",
    "plt.scatter([i for i in range(1, 6)], aggregated_cross_mean, label=\"cross-attention mean\")\n",
    "plt.errorbar([i for i in range(1, 6)], aggregated_self_mean, yerr=aggregated_self_std, fmt='o')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_dataset = generate_dataset_pairs(\"complexity-bias\", 500, 10, model.model_cfg, model.eq_cfg, second_dataset_sample_rate=2)\n",
    "\n",
    "X = complexity_dataset[\"X0\"][0]\n",
    "y = complexity_dataset[\"y0\"][0]\n",
    "\n",
    "print(\"Ground truth function\")\n",
    "sympy.sympify(complexity_dataset[\"equations\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial token prediction, this initializes the sequence and caches the encoder embedding (saves computation time).\n",
    "tok, seq, enc_embed = greedy_predict(model.model, model.params_fit, X.unsqueeze(0), y.unsqueeze(0))\n",
    "\n",
    "# repeatedly predict next token greedily\n",
    "for i in range(30):\n",
    "    seq = greedy_predict(model.model, model.params_fit, enc_embed=enc_embed, sequence=seq)[1]\n",
    "\n",
    "# this should result in (roughly) the correct equation\n",
    "greedy_pred = tokens_to_text(seq, model.params_fit)\n",
    "\n",
    "print(\"Greedy predicted equation:\")\n",
    "for eq in greedy_pred:\n",
    "    display(sympy.sympify(eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with beam search instead of greedy + constant fitting (takes a lot longer)\n",
    "output = fitfunc(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with beam search instead of greedy + constant fitting (takes a lot longer)\n",
    "output = model.fitfunc(X, y)\n",
    "# here you can see the fitted equations\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best BFGS prediction:\")\n",
    "sympy.sympify(output[\"best_bfgs_preds\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
